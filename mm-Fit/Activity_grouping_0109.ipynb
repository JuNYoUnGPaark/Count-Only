{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Pe5vRC64qX",
        "outputId": "36271694-44f9-42d1-bc44-602ecd07fef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 10 subjects from /content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET...\n",
            "\n",
            "================================================================================\n",
            "Trial-level table (first 30)\n",
            "================================================================================\n",
            "     subj  act_id                  activity  gt_count  duration_sec  tempo_rps    T\n",
            " subject1       6       Waist bends forward      21.0         61.44   0.341797 3072\n",
            " subject2       6       Waist bends forward      19.0         63.48   0.299307 3174\n",
            " subject3       6       Waist bends forward      21.0         64.52   0.325480 3226\n",
            " subject4       6       Waist bends forward      20.0         66.56   0.300481 3328\n",
            " subject5       6       Waist bends forward      20.0         55.30   0.361664 2765\n",
            " subject6       6       Waist bends forward      20.0         44.04   0.454133 2202\n",
            " subject7       6       Waist bends forward      20.0         61.44   0.325521 3072\n",
            " subject8       6       Waist bends forward      21.0         43.02   0.488145 2151\n",
            " subject9       6       Waist bends forward      21.0         57.34   0.366236 2867\n",
            "subject10       6       Waist bends forward      20.0         49.16   0.406835 2458\n",
            " subject1       7 Frontal elevation of arms      20.0         61.44   0.325521 3072\n",
            " subject2       7 Frontal elevation of arms      20.0         66.56   0.300481 3328\n",
            " subject3       7 Frontal elevation of arms      20.0         67.58   0.295946 3379\n",
            " subject4       7 Frontal elevation of arms      20.0         65.54   0.305157 3277\n",
            " subject5       7 Frontal elevation of arms      20.0         57.36   0.348675 2868\n",
            " subject6       7 Frontal elevation of arms      20.0         41.98   0.476417 2099\n",
            " subject7       7 Frontal elevation of arms      20.0         55.30   0.361664 2765\n",
            " subject8       7 Frontal elevation of arms      19.0         60.42   0.314465 3021\n",
            " subject9       7 Frontal elevation of arms      19.0         57.34   0.331357 2867\n",
            "subject10       7 Frontal elevation of arms      20.0         55.30   0.361664 2765\n",
            " subject1       8             Knees bending      20.0         67.58   0.295946 3379\n",
            " subject2       8             Knees bending      21.0         68.60   0.306122 3430\n",
            " subject3       8             Knees bending      21.0         63.50   0.330709 3175\n",
            " subject4       8             Knees bending      19.0         62.46   0.304195 3123\n",
            " subject5       8             Knees bending      20.0         54.28   0.368460 2714\n",
            " subject6       8             Knees bending      20.0         46.08   0.434028 2304\n",
            " subject7       8             Knees bending      21.0         56.32   0.372869 2816\n",
            " subject8       8             Knees bending      21.0         51.20   0.410156 2560\n",
            " subject9       8             Knees bending      21.0         59.38   0.353654 2969\n",
            "subject10       8             Knees bending      21.0         57.34   0.366236 2867\n",
            "\n",
            "#Trials=60 | #Activities=6 | Missing=0\n",
            "\n",
            "================================================================================\n",
            "Activity-level summary + groups\n",
            "================================================================================\n",
            "tempo q50 (median of activity mean tempo): 0.676894 reps/sec\n",
            "count threshold (largest adjacent gap midpoint): 89.100000 reps  (gap between 20.500 and 157.700)\n",
            "\n",
            " act_id                  activity  n_trials  tempo_mean_rps  tempo_std_rps  tempo_median_rps  tempo_iqr_rps tempo_group  count_mean  count_std  count_median  count_iqr count_group\n",
            "      7 Frontal elevation of arms        10        0.342135       0.052948          0.328439       0.050932        Slow        19.8   0.421637          20.0       0.00         Low\n",
            "      8             Knees bending        10        0.354238       0.045896          0.359945       0.059498        Slow        20.5   0.707107          21.0       1.00         Low\n",
            "      6       Waist bends forward        10        0.366960       0.064093          0.351730       0.071195        Slow        20.3   0.674949          20.0       1.00         Low\n",
            "     12         Jump front & back        10        0.986828       0.049791          0.976562       0.083576        Fast        20.4   0.843274          20.0       1.00         Low\n",
            "     10                   Jogging        10        2.566732       0.065577          2.547201       0.089518        Fast       157.7   4.029061         156.5       5.50        High\n",
            "     11                   Running        10        2.685547       0.136607          2.693685       0.207520        Fast       165.0   8.393119         165.5      12.75        High\n",
            "\n",
            "Group sizes:\n",
            "tempo_group: {'Slow': 3, 'Fast': 3}\n",
            "count_group: {'Low': 4, 'High': 2}\n",
            "\n",
            "Tempo groups:\n",
            "  Slow: ['Frontal elevation of arms', 'Knees bending', 'Waist bends forward']\n",
            "  Fast: ['Jump front & back', 'Jogging', 'Running']\n",
            "\n",
            "Count-scale groups:\n",
            "  Low: ['Frontal elevation of arms', 'Knees bending', 'Waist bends forward', 'Jump front & back']\n",
            "  High: ['Jogging', 'Running']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Data Loading (from your base code)\n",
        "# ------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"Loading {len(file_list)} subjects from {data_dir}...\")\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "            pass\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Quantification helpers\n",
        "# ------------------------------------------------------------\n",
        "def _iqr(s: pd.Series) -> float:\n",
        "    q1 = s.quantile(0.25)\n",
        "    q3 = s.quantile(0.75)\n",
        "    return float(q3 - q1)\n",
        "\n",
        "\n",
        "def find_largest_gap_threshold(values_1d: np.ndarray):\n",
        "    \"\"\"\n",
        "    Find split threshold by largest adjacent gap (bimodal-friendly).\n",
        "\n",
        "    Args:\n",
        "        values_1d: array-like of activity-level representative values (e.g., count_mean)\n",
        "\n",
        "    Returns:\n",
        "        thr: threshold float\n",
        "        v_sorted: sorted values\n",
        "        j: index of largest gap between v_sorted[j] and v_sorted[j+1]\n",
        "        gaps: all adjacent gaps (len N-1)\n",
        "    \"\"\"\n",
        "    v = np.asarray(values_1d, dtype=np.float64)\n",
        "    v_sorted = np.sort(v)\n",
        "\n",
        "    if v_sorted.size < 2:\n",
        "        return float(v_sorted[0]), v_sorted, 0, np.array([])\n",
        "\n",
        "    gaps = v_sorted[1:] - v_sorted[:-1]\n",
        "    j = int(np.argmax(gaps))\n",
        "    thr = float((v_sorted[j] + v_sorted[j + 1]) / 2.0)\n",
        "    return thr, v_sorted, j, gaps\n",
        "\n",
        "\n",
        "def compute_tempo_and_count_groups(\n",
        "    full_data,\n",
        "    all_labels,             # list of (subj, act_id, gt_count)\n",
        "    target_map,             # {act_id: act_name}\n",
        "    feature_map,            # {act_id: [feature cols]}\n",
        "    fs: float,\n",
        "    print_trials=True,\n",
        "    print_activity_table=True,\n",
        "    save_dir=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Trial tempo:\n",
        "        r_i = C_i / T_i (reps/sec), where T_i = duration_sec = len(raw_df)/fs\n",
        "    Activity tempo summary:\n",
        "        mean/std/median/IQR over r_i\n",
        "\n",
        "    Activity count summary:\n",
        "        mean/std/median/IQR over C_i\n",
        "\n",
        "    Grouping:\n",
        "      - tempo_group (Slow/Fast) by q50 of activity-level mean tempo\n",
        "      - count_group (Low/High) by \"largest adjacent gap\" threshold on activity-level mean count\n",
        "        (robust when counts are bimodal e.g., ~20 vs ~165)\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    missing = 0\n",
        "\n",
        "    # ---- trial-level rows ----\n",
        "    for subj, act_id, gt_count in all_labels:\n",
        "        act_name = target_map.get(act_id)\n",
        "        feats = feature_map.get(act_id)\n",
        "\n",
        "        if act_name is None or feats is None:\n",
        "            missing += 1\n",
        "            continue\n",
        "\n",
        "        if subj not in full_data or act_name not in full_data[subj]:\n",
        "            missing += 1\n",
        "            continue\n",
        "\n",
        "        raw_df = full_data[subj][act_name][feats]   # (T, C)\n",
        "        T = int(len(raw_df))\n",
        "        dur = max(T / float(fs), 1e-6)\n",
        "        r_i = float(gt_count) / dur  # reps/sec\n",
        "\n",
        "        rows.append({\n",
        "            \"subj\": subj,\n",
        "            \"act_id\": int(act_id),\n",
        "            \"activity\": act_name,\n",
        "            \"gt_count\": float(gt_count),\n",
        "            \"T\": T,\n",
        "            \"duration_sec\": dur,\n",
        "            \"tempo_rps\": r_i,\n",
        "        })\n",
        "\n",
        "    trial_df = pd.DataFrame(rows)\n",
        "    if trial_df.empty:\n",
        "        print(\"[Error] No trials collected. Check data_dir / labels / target_map.\")\n",
        "        return trial_df, pd.DataFrame(), {}\n",
        "\n",
        "    if print_trials:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Trial-level table (first 30)\")\n",
        "        print(\"=\" * 80)\n",
        "        cols = [\"subj\", \"act_id\", \"activity\", \"gt_count\", \"duration_sec\", \"tempo_rps\", \"T\"]\n",
        "        print(trial_df[cols].head(30).to_string(index=False))\n",
        "        print(f\"\\n#Trials={len(trial_df)} | #Activities={trial_df['activity'].nunique()} | Missing={missing}\")\n",
        "\n",
        "    # ---- activity-level summaries ----\n",
        "    g = trial_df.groupby([\"act_id\", \"activity\"], as_index=False)\n",
        "\n",
        "    act_df = g.agg(\n",
        "        n_trials=(\"tempo_rps\", \"count\"),\n",
        "\n",
        "        tempo_mean_rps=(\"tempo_rps\", \"mean\"),\n",
        "        tempo_std_rps=(\"tempo_rps\", \"std\"),\n",
        "        tempo_median_rps=(\"tempo_rps\", \"median\"),\n",
        "        tempo_iqr_rps=(\"tempo_rps\", _iqr),\n",
        "\n",
        "        count_mean=(\"gt_count\", \"mean\"),\n",
        "        count_std=(\"gt_count\", \"std\"),\n",
        "        count_median=(\"gt_count\", \"median\"),\n",
        "        count_iqr=(\"gt_count\", _iqr),\n",
        "    )\n",
        "\n",
        "    act_df[\"tempo_std_rps\"] = act_df[\"tempo_std_rps\"].fillna(0.0)\n",
        "    act_df[\"count_std\"] = act_df[\"count_std\"].fillna(0.0)\n",
        "\n",
        "    # ---- tempo split: q50 over activity-level mean tempo ----\n",
        "    tempo_q50 = float(act_df[\"tempo_mean_rps\"].median())\n",
        "    act_df[\"tempo_group\"] = np.where(act_df[\"tempo_mean_rps\"] <= tempo_q50, \"Slow\", \"Fast\")\n",
        "\n",
        "    # ---- count split: largest-gap threshold over activity-level mean count ----\n",
        "    count_thr, sorted_counts, gap_j, gaps = find_largest_gap_threshold(act_df[\"count_mean\"].values)\n",
        "    act_df[\"count_group\"] = np.where(act_df[\"count_mean\"] <= count_thr, \"Low\", \"High\")\n",
        "\n",
        "    # sort for readability\n",
        "    act_df = act_df.sort_values([\"tempo_mean_rps\", \"count_mean\"]).reset_index(drop=True)\n",
        "\n",
        "    thresholds = {\n",
        "        \"tempo_q50_rps\": tempo_q50,\n",
        "        \"count_thr_largest_gap\": count_thr,\n",
        "        \"count_gap_between\": (float(sorted_counts[gap_j]), float(sorted_counts[gap_j + 1])) if sorted_counts.size >= 2 else (None, None),\n",
        "    }\n",
        "\n",
        "    if print_activity_table:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Activity-level summary + groups\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"tempo q50 (median of activity mean tempo): {tempo_q50:.6f} reps/sec\")\n",
        "\n",
        "        if sorted_counts.size >= 2:\n",
        "            a = float(sorted_counts[gap_j])\n",
        "            b = float(sorted_counts[gap_j + 1])\n",
        "            print(f\"count threshold (largest adjacent gap midpoint): {count_thr:.6f} reps  \"\n",
        "                  f\"(gap between {a:.3f} and {b:.3f})\")\n",
        "        else:\n",
        "            print(f\"count threshold (largest-gap): {count_thr:.6f} reps (only one activity)\")\n",
        "\n",
        "        print()\n",
        "\n",
        "        cols = [\n",
        "            \"act_id\", \"activity\", \"n_trials\",\n",
        "            \"tempo_mean_rps\", \"tempo_std_rps\", \"tempo_median_rps\", \"tempo_iqr_rps\", \"tempo_group\",\n",
        "            \"count_mean\", \"count_std\", \"count_median\", \"count_iqr\", \"count_group\",\n",
        "        ]\n",
        "        print(act_df[cols].to_string(index=False))\n",
        "\n",
        "        print(\"\\nGroup sizes:\")\n",
        "        print(\"tempo_group:\", act_df[\"tempo_group\"].value_counts().to_dict())\n",
        "        print(\"count_group:\", act_df[\"count_group\"].value_counts().to_dict())\n",
        "\n",
        "        # optional: group membership lists\n",
        "        print(\"\\nTempo groups:\")\n",
        "        for gname in [\"Slow\", \"Fast\"]:\n",
        "            acts = act_df.loc[act_df[\"tempo_group\"] == gname, \"activity\"].tolist()\n",
        "            print(f\"  {gname}: {acts}\")\n",
        "\n",
        "        print(\"\\nCount-scale groups:\")\n",
        "        for gname in [\"Low\", \"High\"]:\n",
        "            acts = act_df.loc[act_df[\"count_group\"] == gname, \"activity\"].tolist()\n",
        "            print(f\"  {gname}: {acts}\")\n",
        "\n",
        "    if save_dir is not None:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        trial_path = os.path.join(save_dir, \"trial_tempo_count_table.csv\")\n",
        "        act_path = os.path.join(save_dir, \"activity_tempo_count_summary.csv\")\n",
        "        trial_df.to_csv(trial_path, index=False)\n",
        "        act_df.to_csv(act_path, index=False)\n",
        "        print(f\"\\n[Saved] {trial_path}\")\n",
        "        print(f\"[Saved] {act_path}\")\n",
        "\n",
        "    return trial_df, act_df, thresholds\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Main (only for quantification/logging)\n",
        "# ------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "        \"fs\": 50,\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            6:  'Waist bends forward',\n",
        "            7:  'Frontal elevation of arms',\n",
        "            8:  'Knees bending',\n",
        "            10: 'Jogging',\n",
        "            11: 'Running',\n",
        "            12: 'Jump front & back',\n",
        "        },\n",
        "\n",
        "        # Features: only used to select the activity segment length (T)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            6:  ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            7:  ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            8:  ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            10: ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            11: ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "            12: ['acc_chest_x','acc_chest_y','acc_chest_z','acc_ankle_x','acc_ankle_y','acc_ankle_z',\n",
        "                 'gyro_ankle_x','gyro_ankle_y','gyro_ankle_z','acc_arm_x','acc_arm_y','acc_arm_z',\n",
        "                 'gyro_arm_x','gyro_arm_y','gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        \"ALL_LABELS\": [\n",
        "            (\"subject1\", 6, 21), (\"subject2\", 6, 19), (\"subject3\", 6, 21), (\"subject4\", 6, 20), (\"subject5\", 6, 20),\n",
        "            (\"subject6\", 6, 20), (\"subject7\", 6, 20), (\"subject8\", 6, 21), (\"subject9\", 6, 21), (\"subject10\", 6, 20),\n",
        "\n",
        "            (\"subject1\", 7, 20), (\"subject2\", 7, 20), (\"subject3\", 7, 20), (\"subject4\", 7, 20), (\"subject5\", 7, 20),\n",
        "            (\"subject6\", 7, 20), (\"subject7\", 7, 20), (\"subject8\", 7, 19), (\"subject9\", 7, 19), (\"subject10\", 7, 20),\n",
        "\n",
        "            (\"subject1\", 8, 20), (\"subject2\", 8, 21), (\"subject3\", 8, 21), (\"subject4\", 8, 19), (\"subject5\", 8, 20),\n",
        "            (\"subject6\", 8, 20), (\"subject7\", 8, 21), (\"subject8\", 8, 21), (\"subject9\", 8, 21), (\"subject10\", 8, 21),\n",
        "\n",
        "            (\"subject1\", 10, 157), (\"subject2\", 10, 161), (\"subject3\", 10, 154), (\"subject4\", 10, 154), (\"subject5\", 10, 160),\n",
        "            (\"subject6\", 10, 156), (\"subject7\", 10, 153), (\"subject8\", 10, 160), (\"subject9\", 10, 166), (\"subject10\", 10, 156),\n",
        "\n",
        "            (\"subject1\", 11, 165), (\"subject2\", 11, 158), (\"subject3\", 11, 174), (\"subject4\", 11, 163), (\"subject5\", 11, 157),\n",
        "            (\"subject6\", 11, 172), (\"subject7\", 11, 149), (\"subject8\", 11, 166), (\"subject9\", 11, 174), (\"subject10\", 11, 172),\n",
        "\n",
        "            (\"subject1\", 12, 20), (\"subject2\", 12, 22), (\"subject3\", 12, 21), (\"subject4\", 12, 21), (\"subject5\", 12, 20),\n",
        "            (\"subject6\", 12, 21), (\"subject7\", 12, 19), (\"subject8\", 12, 20), (\"subject9\", 12, 20), (\"subject10\", 12, 20),\n",
        "        ],\n",
        "\n",
        "        \"SAVE_DIR\": None,  # e.g., \"/content/drive/MyDrive/tempo_scale_tables\"\n",
        "    }\n",
        "\n",
        "    full_data = load_mhealth_dataset(\n",
        "        CONFIG[\"data_dir\"],\n",
        "        CONFIG[\"TARGET_ACTIVITIES_MAP\"],\n",
        "        CONFIG[\"COLUMN_NAMES\"]\n",
        "    )\n",
        "    if not full_data:\n",
        "        return\n",
        "\n",
        "    compute_tempo_and_count_groups(\n",
        "        full_data=full_data,\n",
        "        all_labels=CONFIG[\"ALL_LABELS\"],\n",
        "        target_map=CONFIG[\"TARGET_ACTIVITIES_MAP\"],\n",
        "        feature_map=CONFIG[\"ACT_FEATURE_MAP\"],\n",
        "        fs=CONFIG[\"fs\"],\n",
        "        print_trials=True,\n",
        "        print_activity_table=True,\n",
        "        save_dir=CONFIG[\"SAVE_DIR\"]\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mm-Fit"
      ],
      "metadata": {
        "id": "6i3W9zSxJAkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) Small utils\n",
        "# ------------------------------------------------------------\n",
        "def _iqr(s: pd.Series) -> float:\n",
        "    q1 = s.quantile(0.25)\n",
        "    q3 = s.quantile(0.75)\n",
        "    return float(q3 - q1)\n",
        "\n",
        "def find_largest_gap_threshold(values_1d: np.ndarray):\n",
        "    v = np.asarray(values_1d, dtype=np.float64)\n",
        "    v_sorted = np.sort(v)\n",
        "\n",
        "    if v_sorted.size < 2:\n",
        "        return float(v_sorted[0]), v_sorted, 0, np.array([])\n",
        "\n",
        "    gaps = v_sorted[1:] - v_sorted[:-1]\n",
        "    j = int(np.argmax(gaps))\n",
        "    thr = float((v_sorted[j] + v_sorted[j + 1]) / 2.0)\n",
        "    return thr, v_sorted, j, gaps\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) MM-Fit signal loader (sw_r acc+gyro 6ch)\n",
        "# ------------------------------------------------------------\n",
        "def load_mmfit_signal(path: str, select_6ch=True):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        X: (T, C) float32\n",
        "        fs: float or None\n",
        "    Supported:\n",
        "        - .npz with keys:\n",
        "            * X  (T,C)    [preferred]\n",
        "            * or acc (T,3) + gyro (T,3)\n",
        "            * optionally fs / sampling_rate\n",
        "        - .npy (T,C)\n",
        "        - .csv / .txt (assumes numeric columns)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        return None, None\n",
        "\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "\n",
        "    fs = None\n",
        "    X = None\n",
        "\n",
        "    try:\n",
        "        if ext == \".npz\":\n",
        "            d = np.load(path, allow_pickle=True)\n",
        "\n",
        "            # fs key candidates\n",
        "            for k in [\"fs\", \"sampling_rate\", \"sr\", \"hz\"]:\n",
        "                if k in d.files:\n",
        "                    try:\n",
        "                        fs = float(np.array(d[k]).squeeze())\n",
        "                        break\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "            if \"X\" in d.files:\n",
        "                X = d[\"X\"]\n",
        "            else:\n",
        "                # fallback: acc + gyro\n",
        "                if (\"acc\" in d.files) and (\"gyro\" in d.files):\n",
        "                    acc = np.asarray(d[\"acc\"], dtype=np.float32)\n",
        "                    gyro = np.asarray(d[\"gyro\"], dtype=np.float32)\n",
        "                    if acc.ndim == 2 and gyro.ndim == 2 and acc.shape[0] == gyro.shape[0]:\n",
        "                        X = np.concatenate([acc, gyro], axis=1)\n",
        "                # another common naming\n",
        "                elif (\"acc_sw_r\" in d.files) and (\"gyro_sw_r\" in d.files):\n",
        "                    acc = np.asarray(d[\"acc_sw_r\"], dtype=np.float32)\n",
        "                    gyro = np.asarray(d[\"gyro_sw_r\"], dtype=np.float32)\n",
        "                    if acc.ndim == 2 and gyro.ndim == 2 and acc.shape[0] == gyro.shape[0]:\n",
        "                        X = np.concatenate([acc, gyro], axis=1)\n",
        "\n",
        "        elif ext == \".npy\":\n",
        "            X = np.load(path).astype(np.float32)\n",
        "\n",
        "        elif ext in [\".csv\", \".txt\"]:\n",
        "            df = pd.read_csv(path)\n",
        "            X = df.values.astype(np.float32)\n",
        "\n",
        "        else:\n",
        "            # unknown\n",
        "            return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[load_mmfit_signal] failed: {path} | {e}\")\n",
        "        return None, None\n",
        "\n",
        "    if X is None:\n",
        "        return None, None\n",
        "\n",
        "    X = np.asarray(X, dtype=np.float32)\n",
        "    if X.ndim != 2:\n",
        "        return None, None\n",
        "\n",
        "    # ✅ keep acc+gyro 6ch by default (first 6 columns)\n",
        "    if select_6ch:\n",
        "        if X.shape[1] < 6:\n",
        "            # not enough channels\n",
        "            return None, fs\n",
        "        X = X[:, :6]\n",
        "\n",
        "    # remove NaN/Inf\n",
        "    if not np.isfinite(X).all():\n",
        "        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
        "\n",
        "    return X, fs\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) MM-Fit meta loader\n",
        "# ------------------------------------------------------------\n",
        "def load_mmfit_meta(meta_csv_path, root_dir, target_exercises, reps_col=\"reps\"):\n",
        "    \"\"\"\n",
        "    meta CSV는 최소한 아래 컬럼이 있으면 됨:\n",
        "      - participant (or subject)\n",
        "      - exercise\n",
        "      - npz_path (or path)\n",
        "      - reps (GT count)\n",
        "      - fs (optional; 없으면 CONFIG fs fallback)\n",
        "\n",
        "    경로는:\n",
        "      - 절대경로면 그대로\n",
        "      - 상대경로면 root_dir 기준으로 join\n",
        "    \"\"\"\n",
        "    if not os.path.exists(meta_csv_path):\n",
        "        raise FileNotFoundError(f\"meta csv not found: {meta_csv_path}\")\n",
        "\n",
        "    meta = pd.read_csv(meta_csv_path)\n",
        "\n",
        "    # column normalization\n",
        "    col_map = {}\n",
        "    if \"participant\" not in meta.columns and \"subject\" in meta.columns:\n",
        "        col_map[\"subject\"] = \"participant\"\n",
        "    if \"npz_path\" not in meta.columns and \"path\" in meta.columns:\n",
        "        col_map[\"path\"] = \"npz_path\"\n",
        "    meta = meta.rename(columns=col_map)\n",
        "\n",
        "    need = [\"participant\", \"exercise\", \"npz_path\", reps_col]\n",
        "    for c in need:\n",
        "        if c not in meta.columns:\n",
        "            raise ValueError(f\"meta csv missing column: {c} (have={list(meta.columns)})\")\n",
        "\n",
        "    meta[\"exercise\"] = meta[\"exercise\"].astype(str).str.strip()\n",
        "    meta = meta[meta[\"exercise\"].isin(set(target_exercises))].copy()\n",
        "\n",
        "    # participant -> int-ish string key\n",
        "    # (MM-Fit이 1,2,3 형태면 \"subject1\"로 바꿔서 통일)\n",
        "    meta[\"participant\"] = pd.to_numeric(meta[\"participant\"], errors=\"coerce\")\n",
        "    meta = meta.dropna(subset=[\"participant\"]).copy()\n",
        "    meta[\"participant\"] = meta[\"participant\"].astype(int)\n",
        "    meta[\"subj_key\"] = meta[\"participant\"].apply(lambda x: f\"subject{x}\")\n",
        "\n",
        "    # build full path\n",
        "    def _full(p):\n",
        "        p = str(p)\n",
        "        if os.path.isabs(p):\n",
        "            return p\n",
        "        return os.path.join(root_dir, p)\n",
        "\n",
        "    meta[\"npz_path_full\"] = meta[\"npz_path\"].apply(_full)\n",
        "    meta = meta[meta[\"npz_path_full\"].apply(os.path.exists)].copy()\n",
        "\n",
        "    # reps numeric\n",
        "    meta[reps_col] = pd.to_numeric(meta[reps_col], errors=\"coerce\")\n",
        "    meta = meta.dropna(subset=[reps_col]).copy()\n",
        "\n",
        "    # fs numeric if exists\n",
        "    if \"fs\" in meta.columns:\n",
        "        meta[\"fs\"] = pd.to_numeric(meta[\"fs\"], errors=\"coerce\")\n",
        "\n",
        "    meta = meta.reset_index(drop=True)\n",
        "    return meta\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Quantification (MM-Fit trial list -> tempo/count summary + grouping)\n",
        "# ------------------------------------------------------------\n",
        "def compute_tempo_and_count_groups_mmfit(\n",
        "    meta_df: pd.DataFrame,\n",
        "    fs_fallback: float,\n",
        "    reps_col=\"reps\",\n",
        "    print_trials=True,\n",
        "    print_activity_table=True,\n",
        "    save_dir=None,\n",
        "    select_6ch=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Trial tempo:\n",
        "        r_i = C_i / T_i (reps/sec), where T_i = duration_sec = len(X)/fs\n",
        "    Activity tempo summary:\n",
        "        mean/std/median/IQR over r_i\n",
        "    Activity count summary:\n",
        "        mean/std/median/IQR over C_i\n",
        "\n",
        "    Grouping:\n",
        "      - tempo_group (Slow/Fast) by q50 of activity-level mean tempo\n",
        "      - count_group (Low/High) by \"largest adjacent gap\" threshold on activity-level mean count\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    missing = 0\n",
        "\n",
        "    for i, row in meta_df.iterrows():\n",
        "        subj = row[\"subj_key\"]\n",
        "        act = row[\"exercise\"]\n",
        "        gt = float(row[reps_col])\n",
        "\n",
        "        path = row[\"npz_path_full\"]\n",
        "\n",
        "        X, fs_from_file = load_mmfit_signal(path, select_6ch=select_6ch)\n",
        "        if X is None:\n",
        "            missing += 1\n",
        "            continue\n",
        "\n",
        "        fs = fs_from_file\n",
        "        if fs is None:\n",
        "            # meta fs가 있으면 그거 사용\n",
        "            if \"fs\" in meta_df.columns and pd.notna(row.get(\"fs\", np.nan)):\n",
        "                fs = float(row[\"fs\"])\n",
        "            else:\n",
        "                fs = float(fs_fallback)\n",
        "\n",
        "        T = int(X.shape[0])\n",
        "        dur = max(T / float(fs), 1e-6)\n",
        "        tempo = gt / dur\n",
        "\n",
        "        # trial identifier: 있으면 쓰고, 없으면 index 사용\n",
        "        trial_id = None\n",
        "        for cand in [\"set_id\", \"trial\", \"rep_id\", \"segment_id\"]:\n",
        "            if cand in meta_df.columns:\n",
        "                trial_id = row[cand]\n",
        "                break\n",
        "        if trial_id is None:\n",
        "            trial_id = i\n",
        "\n",
        "        rows.append({\n",
        "            \"subj\": subj,\n",
        "            \"activity\": act,\n",
        "            \"trial_id\": str(trial_id),\n",
        "            \"gt_count\": gt,\n",
        "            \"T\": T,\n",
        "            \"fs\": float(fs),\n",
        "            \"duration_sec\": dur,\n",
        "            \"tempo_rps\": float(tempo),\n",
        "            \"path\": path,\n",
        "        })\n",
        "\n",
        "    trial_df = pd.DataFrame(rows)\n",
        "    if trial_df.empty:\n",
        "        print(\"[Error] No trials collected. Check meta paths / columns / loader.\")\n",
        "        return trial_df, pd.DataFrame(), {}\n",
        "\n",
        "    if print_trials:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Trial-level table (first 40)\")\n",
        "        print(\"=\" * 80)\n",
        "        cols = [\"subj\", \"activity\", \"trial_id\", \"gt_count\", \"duration_sec\", \"tempo_rps\", \"T\", \"fs\"]\n",
        "        print(trial_df[cols].head(40).to_string(index=False))\n",
        "        print(f\"\\n#Trials={len(trial_df)} | #Activities={trial_df['activity'].nunique()} | Missing={missing}\")\n",
        "\n",
        "    # ---- activity-level summaries ----\n",
        "    g = trial_df.groupby([\"activity\"], as_index=False)\n",
        "\n",
        "    act_df = g.agg(\n",
        "        n_trials=(\"tempo_rps\", \"count\"),\n",
        "\n",
        "        tempo_mean_rps=(\"tempo_rps\", \"mean\"),\n",
        "        tempo_std_rps=(\"tempo_rps\", \"std\"),\n",
        "        tempo_median_rps=(\"tempo_rps\", \"median\"),\n",
        "        tempo_iqr_rps=(\"tempo_rps\", _iqr),\n",
        "\n",
        "        count_mean=(\"gt_count\", \"mean\"),\n",
        "        count_std=(\"gt_count\", \"std\"),\n",
        "        count_median=(\"gt_count\", \"median\"),\n",
        "        count_iqr=(\"gt_count\", _iqr),\n",
        "    )\n",
        "\n",
        "    act_df[\"tempo_std_rps\"] = act_df[\"tempo_std_rps\"].fillna(0.0)\n",
        "    act_df[\"count_std\"] = act_df[\"count_std\"].fillna(0.0)\n",
        "\n",
        "    # tempo split\n",
        "    tempo_q50 = float(act_df[\"tempo_mean_rps\"].median())\n",
        "    act_df[\"tempo_group\"] = np.where(act_df[\"tempo_mean_rps\"] <= tempo_q50, \"Slow\", \"Fast\")\n",
        "\n",
        "    # count split (largest gap)\n",
        "    count_thr, sorted_counts, gap_j, gaps = find_largest_gap_threshold(act_df[\"count_mean\"].values)\n",
        "    act_df[\"count_group\"] = np.where(act_df[\"count_mean\"] <= count_thr, \"Low\", \"High\")\n",
        "\n",
        "    act_df = act_df.sort_values([\"tempo_mean_rps\", \"count_mean\"]).reset_index(drop=True)\n",
        "\n",
        "    thresholds = {\n",
        "        \"tempo_q50_rps\": tempo_q50,\n",
        "        \"count_thr_largest_gap\": count_thr,\n",
        "        \"count_gap_between\": (float(sorted_counts[gap_j]), float(sorted_counts[gap_j + 1])) if sorted_counts.size >= 2 else (None, None),\n",
        "    }\n",
        "\n",
        "    if print_activity_table:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Activity-level summary + groups (MM-Fit)\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"tempo q50 (median of activity mean tempo): {tempo_q50:.6f} reps/sec\")\n",
        "\n",
        "        if sorted_counts.size >= 2:\n",
        "            a = float(sorted_counts[gap_j])\n",
        "            b = float(sorted_counts[gap_j + 1])\n",
        "            print(f\"count threshold (largest adjacent gap midpoint): {count_thr:.6f} reps  \"\n",
        "                  f\"(gap between {a:.3f} and {b:.3f})\")\n",
        "        else:\n",
        "            print(f\"count threshold (largest-gap): {count_thr:.6f} reps (only one activity)\")\n",
        "\n",
        "        print()\n",
        "        cols = [\n",
        "            \"activity\", \"n_trials\",\n",
        "            \"tempo_mean_rps\", \"tempo_std_rps\", \"tempo_median_rps\", \"tempo_iqr_rps\", \"tempo_group\",\n",
        "            \"count_mean\", \"count_std\", \"count_median\", \"count_iqr\", \"count_group\",\n",
        "        ]\n",
        "        print(act_df[cols].to_string(index=False))\n",
        "\n",
        "        print(\"\\nGroup sizes:\")\n",
        "        print(\"tempo_group:\", act_df[\"tempo_group\"].value_counts().to_dict())\n",
        "        print(\"count_group:\", act_df[\"count_group\"].value_counts().to_dict())\n",
        "\n",
        "        print(\"\\nTempo groups:\")\n",
        "        for gname in [\"Slow\", \"Fast\"]:\n",
        "            acts = act_df.loc[act_df[\"tempo_group\"] == gname, \"activity\"].tolist()\n",
        "            print(f\"  {gname}: {acts}\")\n",
        "\n",
        "        print(\"\\nCount-scale groups:\")\n",
        "        for gname in [\"Low\", \"High\"]:\n",
        "            acts = act_df.loc[act_df[\"count_group\"] == gname, \"activity\"].tolist()\n",
        "            print(f\"  {gname}: {acts}\")\n",
        "\n",
        "    if save_dir is not None:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        trial_path = os.path.join(save_dir, \"mmfit_trial_tempo_count_table.csv\")\n",
        "        act_path = os.path.join(save_dir, \"mmfit_activity_tempo_count_summary.csv\")\n",
        "        trial_df.to_csv(trial_path, index=False)\n",
        "        act_df.to_csv(act_path, index=False)\n",
        "        print(f\"\\n[Saved] {trial_path}\")\n",
        "        print(f\"[Saved] {act_path}\")\n",
        "\n",
        "    return trial_df, act_df, thresholds\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Main\n",
        "# ------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"ROOT_DIR\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials\",\n",
        "        \"META_CSV\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/mmfit_imu_3ex_trials/meta_sw_r_dumbbell_rows_lunges_pushups.csv\",\n",
        "\n",
        "        \"TARGET_EXERCISES\": [\n",
        "            \"pushups\",\n",
        "            \"lunges\",\n",
        "            \"dumbbell_rows\",\n",
        "        ],\n",
        "\n",
        "        # ✅ CSV에 따라 컬럼명 다름 (이 파일은 'repetition' 컬럼 사용)\n",
        "        \"REPS_COL\": \"reps\",\n",
        "\n",
        "        \"FS_FALLBACK\": 100.0,   # fps30 → sampling rate 30Hz\n",
        "        \"SELECT_6CH\": True,\n",
        "        \"SAVE_DIR\": None,\n",
        "    }\n",
        "\n",
        "    meta = load_mmfit_meta(\n",
        "        meta_csv_path=CONFIG[\"META_CSV\"],\n",
        "        root_dir=CONFIG[\"ROOT_DIR\"],\n",
        "        target_exercises=CONFIG[\"TARGET_EXERCISES\"],\n",
        "        reps_col=CONFIG[\"REPS_COL\"]\n",
        "    )\n",
        "\n",
        "    if meta.empty:\n",
        "        print(\"[Error] meta after filtering is empty. Check exercise names / paths / reps col.\")\n",
        "        return\n",
        "\n",
        "    compute_tempo_and_count_groups_mmfit(\n",
        "        meta_df=meta,\n",
        "        fs_fallback=CONFIG[\"FS_FALLBACK\"],\n",
        "        reps_col=CONFIG[\"REPS_COL\"],\n",
        "        print_trials=True,\n",
        "        print_activity_table=True,\n",
        "        save_dir=CONFIG[\"SAVE_DIR\"],\n",
        "        select_6ch=CONFIG[\"SELECT_6CH\"],\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll1Ck042I9gk",
        "outputId": "c79c4fd1-392c-468e-8a36-de4d4a0c1684"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Trial-level table (first 40)\n",
            "================================================================================\n",
            "    subj      activity trial_id  gt_count  duration_sec  tempo_rps    T    fs\n",
            "subject2       pushups        1      10.0         14.19   0.704722 1419 100.0\n",
            "subject2       pushups        2      10.0         12.66   0.789889 1266 100.0\n",
            "subject2        lunges        3      10.0         28.08   0.356125 2808 100.0\n",
            "subject2        lunges        4      10.0         27.83   0.359324 2783 100.0\n",
            "subject2        lunges        5      10.0         29.29   0.341413 2929 100.0\n",
            "subject2 dumbbell_rows        6      11.0         17.50   0.628571 1750 100.0\n",
            "subject2 dumbbell_rows        7      10.0         15.17   0.659196 1517 100.0\n",
            "subject2 dumbbell_rows        8      11.0         16.65   0.660661 1665 100.0\n",
            "subject0       pushups        0      10.0         11.87   0.842460 1187 100.0\n",
            "subject0       pushups        1      10.0         15.14   0.660502 1514 100.0\n",
            "subject0       pushups        2      10.0         16.00   0.625000 1600 100.0\n",
            "subject0        lunges        3      10.0         28.49   0.351000 2849 100.0\n",
            "subject0        lunges        4      10.0         23.50   0.425532 2350 100.0\n",
            "subject0        lunges        5      10.0         25.49   0.392311 2549 100.0\n",
            "subject0 dumbbell_rows        6      10.0         20.43   0.489476 2043 100.0\n",
            "subject0 dumbbell_rows        7      10.0         20.86   0.479386 2086 100.0\n",
            "subject0 dumbbell_rows        8      10.0         20.66   0.484027 2066 100.0\n",
            "subject0 dumbbell_rows        9      10.0         17.73   0.564016 1773 100.0\n",
            "subject1       pushups        0      10.0         15.56   0.642674 1556 100.0\n",
            "subject1       pushups        1      10.0         14.96   0.668449 1496 100.0\n",
            "subject1       pushups        2      10.0         13.73   0.728332 1373 100.0\n",
            "subject1        lunges        3      10.0         26.42   0.378501 2642 100.0\n",
            "subject1        lunges        4      10.0         28.13   0.355492 2813 100.0\n",
            "subject1        lunges        5      10.0         28.40   0.352113 2840 100.0\n",
            "subject1 dumbbell_rows        6      10.0         18.96   0.527426 1896 100.0\n",
            "subject1 dumbbell_rows        7      10.0         17.24   0.580046 1724 100.0\n",
            "subject1 dumbbell_rows        8      10.0         15.99   0.625391 1599 100.0\n",
            "subject0       pushups        0      10.0         15.60   0.641026 1560 100.0\n",
            "subject0       pushups        1      10.0         16.53   0.604961 1653 100.0\n",
            "subject0       pushups        2      10.0         14.99   0.667111 1499 100.0\n",
            "subject0        lunges        3      10.0         26.16   0.382263 2616 100.0\n",
            "subject0        lunges        4      10.0         26.16   0.382263 2616 100.0\n",
            "subject0        lunges        5      10.0         26.30   0.380228 2630 100.0\n",
            "subject0 dumbbell_rows        6      10.0         18.10   0.552486 1810 100.0\n",
            "subject0 dumbbell_rows        7      10.0         17.80   0.561798 1780 100.0\n",
            "subject0 dumbbell_rows        8      10.0         18.32   0.545852 1832 100.0\n",
            "subject1       pushups        0      10.0         15.19   0.658328 1519 100.0\n",
            "subject1       pushups        1      10.0         14.89   0.671592 1489 100.0\n",
            "subject1       pushups        2      10.0         15.79   0.633312 1579 100.0\n",
            "subject1        lunges        3      10.0         30.12   0.332005 3012 100.0\n",
            "\n",
            "#Trials=189 | #Activities=3 | Missing=0\n",
            "\n",
            "================================================================================\n",
            "Activity-level summary + groups (MM-Fit)\n",
            "================================================================================\n",
            "tempo q50 (median of activity mean tempo): 0.596782 reps/sec\n",
            "count threshold (largest adjacent gap midpoint): 10.016121 reps  (gap between 9.969 and 10.063)\n",
            "\n",
            "     activity  n_trials  tempo_mean_rps  tempo_std_rps  tempo_median_rps  tempo_iqr_rps tempo_group  count_mean  count_std  count_median  count_iqr count_group\n",
            "       lunges        62        0.361004       0.037634          0.356252       0.043426        Slow   10.064516   0.539306          10.0        0.0        High\n",
            "dumbbell_rows        63        0.596782       0.112065          0.568505       0.105536        Slow   10.063492   0.304431          10.0        0.0        High\n",
            "      pushups        64        0.632179       0.121093          0.641850       0.137153        Fast    9.968750   0.470351          10.0        0.0         Low\n",
            "\n",
            "Group sizes:\n",
            "tempo_group: {'Slow': 2, 'Fast': 1}\n",
            "count_group: {'High': 2, 'Low': 1}\n",
            "\n",
            "Tempo groups:\n",
            "  Slow: ['lunges', 'dumbbell_rows']\n",
            "  Fast: ['pushups']\n",
            "\n",
            "Count-scale groups:\n",
            "  Low: ['pushups']\n",
            "  High: ['lunges', 'dumbbell_rows']\n"
          ]
        }
      ]
    }
  ]
}